{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "33c91cae-2ff8-45a6-b8cb-671619e9c933",
    "_uuid": "0a395fd25f20834b070ef55cb8987c8c1f9b55f9"
   },
   "source": [
    "---\n",
    "title: 타이타닉 생존자 예측 V2\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de05512e-6991-44df-9599-da92a7e459ac",
    "_uuid": "d8bdd5f0320e244e4702ed8ec1c2482b022c51cd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e0a17223-f682-45fc-89a5-667af9782bbe",
    "_uuid": "7964157913fbcff581fc1929eed487708e81ac9c"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/titanic_train.csv\")\n",
    "test_df = pd.read_csv(\"data/titanic_test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d969b76-ea88-4d32-a58e-f22a070258bf",
    "_uuid": "bff38fcf31baf67493513c06f0c2f6e50576ff09"
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "29dddd33-d995-4b0f-92ea-a361b368cc42",
    "_uuid": "d4fe22ead7e187724ca6f3ba7ba0e6412ae0e874"
   },
   "outputs": [],
   "source": [
    "# check missing values in train data\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6d65fcfa-52bf-45ab-b959-64a32c1c1976",
    "_uuid": "c6fd60f15d5e803d4dffc89e782c6fbc72445a83"
   },
   "outputs": [],
   "source": [
    "ax = train_df[\"Age\"].hist(bins=15, density=True, stacked=True, color=\"teal\", alpha=0.6)\n",
    "train_df[\"Age\"].plot(kind=\"density\", color=\"teal\")\n",
    "ax.set(xlabel=\"Age\")\n",
    "plt.xlim(-10, 85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d70c27b-1e4d-4d5e-8a39-c134389d436c",
    "_uuid": "4f13840d4f9bf1b4331523c99274aa0627485e6c"
   },
   "outputs": [],
   "source": [
    "# mean age\n",
    "print('The mean of \"Age\" is %.2f' % (train_df[\"Age\"].mean(skipna=True)))\n",
    "# median age\n",
    "print('The median of \"Age\" is %.2f' % (train_df[\"Age\"].median(skipna=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a1ad808-0a63-43ac-b757-71195880ed4f",
    "_uuid": "1acbce9c6bc5d586dda3e47b7506067a85524e66"
   },
   "outputs": [],
   "source": [
    "# percent of missing \"Cabin\"\n",
    "print(\n",
    "    'Percent of missing \"Cabin\" records is %.2f%%'\n",
    "    % ((train_df[\"Cabin\"].isnull().sum() / train_df.shape[0]) * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f21c2b55-2126-439d-8b1d-e96dafc97d81",
    "_uuid": "92ab9e62fb62f2a0fb9972baf6ada444187540e6"
   },
   "outputs": [],
   "source": [
    "# percent of missing \"Embarked\"\n",
    "print(\n",
    "    'Percent of missing \"Embarked\" records is %.2f%%'\n",
    "    % ((train_df[\"Embarked\"].isnull().sum() / train_df.shape[0]) * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22924bc4-5dfa-4df7-b0d0-de3ede9c58b7",
    "_uuid": "f2a915f45264f8a580de6cc382d96b370eb75730"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Boarded passengers grouped by port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton):\"\n",
    ")\n",
    "print(train_df[\"Embarked\"].value_counts())\n",
    "sns.countplot(x=\"Embarked\", data=train_df, palette=\"Set2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "def67427-3257-4dce-872e-7f5b4202d18a",
    "_uuid": "c57a9f8a54efa382bc94b695c9664330d01709ea"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The most common boarding port of embarkation is %s.\"\n",
    "    % train_df[\"Embarked\"].value_counts().idxmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bc0d7121-1008-4890-9043-07eba1524e15",
    "_uuid": "feeed4b6775f88edf5de12b0ee6ee73c16eba61d"
   },
   "outputs": [],
   "source": [
    "train_data = train_df.copy()\n",
    "train_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\n",
    "train_data[\"Embarked\"].fillna(\n",
    "    train_df[\"Embarked\"].value_counts().idxmax(), inplace=True\n",
    ")\n",
    "train_data.drop(\"Cabin\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0cfe1c08-71a6-493e-803d-db255af01697",
    "_uuid": "d6be29651bb903964e02d3a7bcc7033513eb76c9"
   },
   "outputs": [],
   "source": [
    "# check missing values in adjusted train data\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "10dcfe1b-34f1-4bd8-b937-5ae8daf4a378",
    "_uuid": "3ee37b1151416aeeec8ebd7b94bb0184aabc57cd"
   },
   "outputs": [],
   "source": [
    "# preview adjusted train data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dda26046-b93b-49ee-a52e-35355ecb425c",
    "_uuid": "293aec20df86ef529d10ae1f051dfe921ba07b88"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "ax = train_df[\"Age\"].hist(bins=15, density=True, stacked=True, color=\"teal\", alpha=0.6)\n",
    "train_df[\"Age\"].plot(kind=\"density\", color=\"teal\")\n",
    "ax = train_data[\"Age\"].hist(\n",
    "    bins=15, density=True, stacked=True, color=\"orange\", alpha=0.5\n",
    ")\n",
    "train_data[\"Age\"].plot(kind=\"density\", color=\"orange\")\n",
    "ax.legend([\"Raw Age\", \"Adjusted Age\"])\n",
    "ax.set(xlabel=\"Age\")\n",
    "plt.xlim(-10, 85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "759c3c8e-8db6-41d9-a1a2-058a15b338a6",
    "_uuid": "d1f5815ba663f7e8cc17d7efcff73653af5b1bdb"
   },
   "outputs": [],
   "source": [
    "## Create categorical variable for traveling alone\n",
    "train_data[\"TravelAlone\"] = np.where(\n",
    "    (train_data[\"SibSp\"] + train_data[\"Parch\"]) > 0, 0, 1\n",
    ")\n",
    "train_data.drop(\"SibSp\", axis=1, inplace=True)\n",
    "train_data.drop(\"Parch\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f95361e8-2533-4731-a7ab-a99cf686ed50",
    "_uuid": "4494fcbf9faa90151e20042f74d73395fac3cc8e"
   },
   "outputs": [],
   "source": [
    "# create categorical variables and drop some variables\n",
    "training = pd.get_dummies(train_data, columns=[\"Pclass\", \"Embarked\", \"Sex\"])\n",
    "training.drop(\"Sex_female\", axis=1, inplace=True)\n",
    "training.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "training.drop(\"Name\", axis=1, inplace=True)\n",
    "training.drop(\"Ticket\", axis=1, inplace=True)\n",
    "\n",
    "final_train = training\n",
    "final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "501f9a53-881d-4440-9366-7aae67eb358b",
    "_uuid": "d80416a026d17ccac3bf793408dd5f4f1e17bf63"
   },
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8b9ef076-3669-4339-8d10-0d8783a92e07",
    "_uuid": "145675b90aa2befa533c640aaedd4bf8069b12d4"
   },
   "outputs": [],
   "source": [
    "test_data = test_df.copy()\n",
    "test_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\n",
    "test_data[\"Fare\"].fillna(train_df[\"Fare\"].median(skipna=True), inplace=True)\n",
    "test_data.drop(\"Cabin\", axis=1, inplace=True)\n",
    "\n",
    "test_data[\"TravelAlone\"] = np.where((test_data[\"SibSp\"] + test_data[\"Parch\"]) > 0, 0, 1)\n",
    "\n",
    "test_data.drop(\"SibSp\", axis=1, inplace=True)\n",
    "test_data.drop(\"Parch\", axis=1, inplace=True)\n",
    "\n",
    "testing = pd.get_dummies(test_data, columns=[\"Pclass\", \"Embarked\", \"Sex\"])\n",
    "testing.drop(\"Sex_female\", axis=1, inplace=True)\n",
    "testing.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "testing.drop(\"Name\", axis=1, inplace=True)\n",
    "testing.drop(\"Ticket\", axis=1, inplace=True)\n",
    "\n",
    "final_test = testing\n",
    "final_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9f9ca9e5-50a0-4487-ba53-815dda90af1c",
    "_uuid": "790e8d7ca89d19e276b3398e299c42893a796b79"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.kdeplot(\n",
    "    final_train[\"Age\"][final_train.Survived == 1], color=\"darkturquoise\", shade=True\n",
    ")\n",
    "sns.kdeplot(\n",
    "    final_train[\"Age\"][final_train.Survived == 0], color=\"lightcoral\", shade=True\n",
    ")\n",
    "plt.legend([\"Survived\", \"Died\"])\n",
    "plt.title(\"Density Plot of Age for Surviving Population and Deceased Population\")\n",
    "ax.set(xlabel=\"Age\")\n",
    "plt.xlim(-10, 85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d2aa9f59-c433-4258-b8db-225b63a5eab6",
    "_uuid": "9cf1794d9db2fdc314c20ca97a76e9470e81a354"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "avg_survival_byage = (\n",
    "    final_train[[\"Age\", \"Survived\"]].groupby([\"Age\"], as_index=False).mean()\n",
    ")\n",
    "g = sns.barplot(x=\"Age\", y=\"Survived\", data=avg_survival_byage, color=\"LightSeaGreen\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1655b49b-b33f-4236-8b31-d995ef26c6f6",
    "_uuid": "8918defa6e17b83c700ea45357ebd67a3a22f02f"
   },
   "outputs": [],
   "source": [
    "final_train[\"IsMinor\"] = np.where(final_train[\"Age\"] <= 16, 1, 0)\n",
    "final_test[\"IsMinor\"] = np.where(final_test[\"Age\"] <= 16, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9f31ffe1-7cd8-4169-b193-ed44e56d0bd4",
    "_uuid": "4a1c521f08460f6983eca0c4e01294fb7c86e4f9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.kdeplot(\n",
    "    final_train[\"Fare\"][final_train.Survived == 1], color=\"darkturquoise\", shade=True\n",
    ")\n",
    "sns.kdeplot(\n",
    "    final_train[\"Fare\"][final_train.Survived == 0], color=\"lightcoral\", shade=True\n",
    ")\n",
    "plt.legend([\"Survived\", \"Died\"])\n",
    "plt.title(\"Density Plot of Fare for Surviving Population and Deceased Population\")\n",
    "ax.set(xlabel=\"Fare\")\n",
    "plt.xlim(-20, 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "676548e8-6dd4-4180-800c-7b164acb3877",
    "_uuid": "08fd677214959e0b938a0f8a94b63ab548673ea5"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Pclass\", y=\"Survived\", data=train_df, color=\"darkturquoise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6e5bec50-2f5e-433e-9130-c56956fddad3",
    "_uuid": "a9f0598701c7c5224eaa73dafa869af73beffe18"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Embarked\", y=\"Survived\", data=train_df, color=\"teal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "67017a88-93d4-412b-9adf-8b4d1d9b9db0",
    "_uuid": "e0c3dc16292ef0bcabf0fc680d821ef654084ab4"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"TravelAlone\", y=\"Survived\", data=final_train, color=\"mediumturquoise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7b416e59-8616-4a44-93e1-a8005eff78a9",
    "_uuid": "354794315925dff1e96229cc737eaf299aaea17a"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Sex\", y=\"Survived\", data=train_df, color=\"aquamarine\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "11a2a468-20df-40cd-a4ba-4ae7bd2fc403",
    "_uuid": "64befdf1182c2b4e845f488f5bfd0e19ce3dc17a"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "cols = [\n",
    "    \"Age\",\n",
    "    \"Fare\",\n",
    "    \"TravelAlone\",\n",
    "    \"Pclass_1\",\n",
    "    \"Pclass_2\",\n",
    "    \"Embarked_C\",\n",
    "    \"Embarked_S\",\n",
    "    \"Sex_male\",\n",
    "    \"IsMinor\",\n",
    "]\n",
    "X = final_train[cols]\n",
    "y = final_train[\"Survived\"]\n",
    "# Build a logreg and compute the feature importances\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 8 attributes\n",
    "rfe = RFE(model)\n",
    "rfe = rfe.fit(X, y)\n",
    "# summarize the selection of the attributes\n",
    "print(\"Selected features: %s\" % list(X.columns[rfe.support_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7239aa6f-7fd2-4b75-a387-f6624f1c338c",
    "_uuid": "53d79f38cfe33d75d6ff869a443b9a29c93b4cbd"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "rfecv = RFECV(estimator=LogisticRegression(), step=1, cv=10, scoring=\"accuracy\")\n",
    "rfecv.fit(X, y)\n",
    "print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
    "print(\"Selected features: %s\" % list(X.columns[rfecv.support_]))\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.cv_results_) + 1), rfecv.cv_results_.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "08986ec4-79ff-466b-b763-61bf84a0879b",
    "_uuid": "3f6950a7c24c629b72e17e54c556f3c183b3f779"
   },
   "outputs": [],
   "source": [
    "Selected_features = [\n",
    "    \"Age\",\n",
    "    \"TravelAlone\",\n",
    "    \"Pclass_1\",\n",
    "    \"Pclass_2\",\n",
    "    \"Embarked_C\",\n",
    "    \"Embarked_S\",\n",
    "    \"Sex_male\",\n",
    "    \"IsMinor\",\n",
    "]\n",
    "X = final_train[Selected_features]\n",
    "\n",
    "plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(X.corr(), annot=True, cmap=\"RdYlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "84233f59-f3c7-4ea0-884d-96f8ad4d5b10",
    "_uuid": "46336228eeb864bc82e6739768122579d1c9634c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    log_loss,\n",
    ")\n",
    "\n",
    "# create X (features) and y (response)\n",
    "X = final_train[Selected_features]\n",
    "y = final_train[\"Survived\"]\n",
    "\n",
    "# use train/test split with different random_state values\n",
    "# we can change the random_state values that changes the accuracy scores\n",
    "# the scores change a lot, this is why testing scores is a high-variance estimate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# check classification scores of logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\n",
    "print(\"Train/Test split results:\")\n",
    "print(logreg.__class__.__name__ + \" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(logreg.__class__.__name__ + \" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\n",
    "print(logreg.__class__.__name__ + \" auc is %2.3f\" % auc(fpr, tpr))\n",
    "\n",
    "idx = np.min(\n",
    "    np.where(tpr > 0.95)\n",
    ")  # index of the first threshold for which the sensibility > 0.95\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color=\"coral\", label=\"ROC curve (area = %0.3f)\" % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.plot([0, fpr[idx]], [tpr[idx], tpr[idx]], \"k--\", color=\"blue\")\n",
    "plt.plot([fpr[idx], fpr[idx]], [0, tpr[idx]], \"k--\", color=\"blue\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate (1 - specificity)\", fontsize=14)\n",
    "plt.ylabel(\"True Positive Rate (recall)\", fontsize=14)\n",
    "plt.title(\"Receiver operating characteristic (ROC) curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"Using a threshold of %.3f \" % thr[idx]\n",
    "    + \"guarantees a sensitivity of %.3f \" % tpr[idx]\n",
    "    + \"and a specificity of %.3f\" % (1 - fpr[idx])\n",
    "    + \", i.e. a false positive rate of %.2f%%.\" % (np.array(fpr[idx]) * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "32a611ae-b2b7-43e0-8fa8-3cc56e351bf6",
    "_uuid": "7f0aba7b861c3fa1748060b4733778851fb00a31"
   },
   "outputs": [],
   "source": [
    "# 10-fold cross-validation logistic regression\n",
    "logreg = LogisticRegression()\n",
    "# Use cross_val_score function\n",
    "# We are passing the entirety of X and y, not X_train or y_train, it takes care of splitting the data\n",
    "# cv=10 for 10 folds\n",
    "# scoring = {'accuracy', 'neg_log_loss', 'roc_auc'} for evaluation metric - althought they are many\n",
    "scores_accuracy = cross_val_score(logreg, X, y, cv=10, scoring=\"accuracy\")\n",
    "scores_log_loss = cross_val_score(logreg, X, y, cv=10, scoring=\"neg_log_loss\")\n",
    "scores_auc = cross_val_score(logreg, X, y, cv=10, scoring=\"roc_auc\")\n",
    "print(\"K-fold cross-validation results:\")\n",
    "print(logreg.__class__.__name__ + \" average accuracy is %2.3f\" % scores_accuracy.mean())\n",
    "print(\n",
    "    logreg.__class__.__name__ + \" average log_loss is %2.3f\" % -scores_log_loss.mean()\n",
    ")\n",
    "print(logreg.__class__.__name__ + \" average auc is %2.3f\" % scores_auc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9ea95aac-00b2-413e-ab86-c6b8782c40ef",
    "_uuid": "90840c89d42e9284c9480a256dc259778c3a5b1b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = {\"accuracy\": \"accuracy\", \"log_loss\": \"neg_log_loss\", \"auc\": \"roc_auc\"}\n",
    "\n",
    "modelCV = LogisticRegression()\n",
    "\n",
    "results = cross_validate(\n",
    "    modelCV, X, y, cv=10, scoring=list(scoring.values()), return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"K-fold cross-validation results:\")\n",
    "for sc in range(len(scoring)):\n",
    "    print(\n",
    "        modelCV.__class__.__name__\n",
    "        + \" average %s: %.3f (+/-%.3f)\"\n",
    "        % (\n",
    "            list(scoring.keys())[sc],\n",
    "            (\n",
    "                -results[\"test_%s\" % list(scoring.values())[sc]].mean()\n",
    "                if list(scoring.values())[sc] == \"neg_log_loss\"\n",
    "                else results[\"test_%s\" % list(scoring.values())[sc]].mean()\n",
    "            ),\n",
    "            results[\"test_%s\" % list(scoring.values())[sc]].std(),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "80b5d5c3-ead3-48f7-84eb-42c801e0370a",
    "_uuid": "0fdf4a257a49b0b47552a4ed307c86852c4ed271"
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"Age\",\n",
    "    \"Fare\",\n",
    "    \"TravelAlone\",\n",
    "    \"Pclass_1\",\n",
    "    \"Pclass_2\",\n",
    "    \"Embarked_C\",\n",
    "    \"Embarked_S\",\n",
    "    \"Sex_male\",\n",
    "    \"IsMinor\",\n",
    "]\n",
    "X = final_train[cols]\n",
    "\n",
    "scoring = {\"accuracy\": \"accuracy\", \"log_loss\": \"neg_log_loss\", \"auc\": \"roc_auc\"}\n",
    "\n",
    "modelCV = LogisticRegression()\n",
    "\n",
    "results = cross_validate(\n",
    "    modelCV,\n",
    "    final_train[cols],\n",
    "    y,\n",
    "    cv=10,\n",
    "    scoring=list(scoring.values()),\n",
    "    return_train_score=False,\n",
    ")\n",
    "\n",
    "print(\"K-fold cross-validation results:\")\n",
    "for sc in range(len(scoring)):\n",
    "    print(\n",
    "        modelCV.__class__.__name__\n",
    "        + \" average %s: %.3f (+/-%.3f)\"\n",
    "        % (\n",
    "            list(scoring.keys())[sc],\n",
    "            (\n",
    "                -results[\"test_%s\" % list(scoring.values())[sc]].mean()\n",
    "                if list(scoring.values())[sc] == \"neg_log_loss\"\n",
    "                else results[\"test_%s\" % list(scoring.values())[sc]].mean()\n",
    "            ),\n",
    "            results[\"test_%s\" % list(scoring.values())[sc]].std(),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4a39cb49-b446-4ffa-88a2-e37b627eb5e5",
    "_uuid": "765695a9712d3fe1ecff10f17dcc077a80ed7682"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = final_train[Selected_features]\n",
    "\n",
    "param_grid = {\"C\": np.arange(1e-05, 3, 0.1)}\n",
    "scoring = {\"Accuracy\": \"accuracy\", \"AUC\": \"roc_auc\", \"Log_loss\": \"neg_log_loss\"}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    return_train_score=True,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    cv=10,\n",
    "    refit=\"Accuracy\",\n",
    ")\n",
    "\n",
    "gs.fit(X, y)\n",
    "results = gs.cv_results_\n",
    "\n",
    "print(\"=\" * 20)\n",
    "print(\"best params: \" + str(gs.best_estimator_))\n",
    "print(\"best params: \" + str(gs.best_params_))\n",
    "print(\"best score:\", gs.best_score_)\n",
    "print(\"=\" * 20)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\", fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Inverse of regularization strength: C\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_xlim(0, param_grid[\"C\"].max())\n",
    "ax.set_ylim(0.35, 0.95)\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "X_axis = np.array(results[\"param_C\"].data, dtype=float)\n",
    "\n",
    "for scorer, color in zip(list(scoring.keys()), [\"g\", \"k\", \"b\"]):\n",
    "    for sample, style in ((\"train\", \"--\"), (\"test\", \"-\")):\n",
    "        sample_score_mean = (\n",
    "            -results[\"mean_%s_%s\" % (sample, scorer)]\n",
    "            if scoring[scorer] == \"neg_log_loss\"\n",
    "            else results[\"mean_%s_%s\" % (sample, scorer)]\n",
    "        )\n",
    "        sample_score_std = results[\"std_%s_%s\" % (sample, scorer)]\n",
    "        ax.fill_between(\n",
    "            X_axis,\n",
    "            sample_score_mean - sample_score_std,\n",
    "            sample_score_mean + sample_score_std,\n",
    "            alpha=0.1 if sample == \"test\" else 0,\n",
    "            color=color,\n",
    "        )\n",
    "        ax.plot(\n",
    "            X_axis,\n",
    "            sample_score_mean,\n",
    "            style,\n",
    "            color=color,\n",
    "            alpha=1 if sample == \"test\" else 0.7,\n",
    "            label=\"%s (%s)\" % (scorer, sample),\n",
    "        )\n",
    "\n",
    "    best_index = np.nonzero(results[\"rank_test_%s\" % scorer] == 1)[0][0]\n",
    "    best_score = (\n",
    "        -results[\"mean_test_%s\" % scorer][best_index]\n",
    "        if scoring[scorer] == \"neg_log_loss\"\n",
    "        else results[\"mean_test_%s\" % scorer][best_index]\n",
    "    )\n",
    "\n",
    "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "    ax.plot(\n",
    "        [\n",
    "            X_axis[best_index],\n",
    "        ]\n",
    "        * 2,\n",
    "        [0, best_score],\n",
    "        linestyle=\"-.\",\n",
    "        color=color,\n",
    "        marker=\"x\",\n",
    "        markeredgewidth=3,\n",
    "        ms=8,\n",
    "    )\n",
    "\n",
    "    # Annotate the best score for that scorer\n",
    "    ax.annotate(\"%0.2f\" % best_score, (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 및 매개변수 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a777c645-7413-4e1d-855a-0b416be1b48e",
    "_uuid": "514d0e3aabe57aaad38d10d6101dbdac5af89ca4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define simple model\n",
    "###############################################################################\n",
    "C = np.arange(1e-05, 5.5, 0.1)\n",
    "scoring = {\"Accuracy\": \"accuracy\", \"AUC\": \"roc_auc\", \"Log_loss\": \"neg_log_loss\"}\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Simple pre-processing estimators\n",
    "###############################################################################\n",
    "std_scale = StandardScaler(with_mean=False, with_std=False)\n",
    "# std_scale = StandardScaler()\n",
    "\n",
    "# Defining the CV method: Using the Repeated Stratified K Fold\n",
    "###############################################################################\n",
    "\n",
    "n_folds = 5\n",
    "n_repeats = 5\n",
    "\n",
    "rskfold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=n_repeats, random_state=2)\n",
    "\n",
    "# Creating simple pipeline and defining the gridsearch\n",
    "###############################################################################\n",
    "log_clf_pipe = Pipeline(steps=[(\"scale\", std_scale), (\"clf\", log_reg)])\n",
    "log_clf = GridSearchCV(\n",
    "    estimator=log_clf_pipe,\n",
    "    cv=rskfold,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    param_grid=dict(clf__C=C),\n",
    "    refit=\"Accuracy\",\n",
    ")\n",
    "log_clf.fit(X, y)\n",
    "results = log_clf.cv_results_\n",
    "print(\"=\" * 20)\n",
    "print(\"best params: \" + str(log_clf.best_estimator_))\n",
    "print(\"best params: \" + str(log_clf.best_params_))\n",
    "print(\"best score:\", log_clf.best_score_)\n",
    "print(\"=\" * 20)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\", fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Inverse of regularization strength: C\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_xlim(0, C.max())\n",
    "ax.set_ylim(0.35, 0.95)\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "X_axis = np.array(results[\"param_clf__C\"].data, dtype=float)\n",
    "\n",
    "for scorer, color in zip(list(scoring.keys()), [\"g\", \"k\", \"b\"]):\n",
    "    for sample, style in ((\"train\", \"--\"), (\"test\", \"-\")):\n",
    "        sample_score_mean = (\n",
    "            -results[\"mean_%s_%s\" % (sample, scorer)]\n",
    "            if scoring[scorer] == \"neg_log_loss\"\n",
    "            else results[\"mean_%s_%s\" % (sample, scorer)]\n",
    "        )\n",
    "        sample_score_std = results[\"std_%s_%s\" % (sample, scorer)]\n",
    "        ax.fill_between(\n",
    "            X_axis,\n",
    "            sample_score_mean - sample_score_std,\n",
    "            sample_score_mean + sample_score_std,\n",
    "            alpha=0.1 if sample == \"test\" else 0,\n",
    "            color=color,\n",
    "        )\n",
    "        ax.plot(\n",
    "            X_axis,\n",
    "            sample_score_mean,\n",
    "            style,\n",
    "            color=color,\n",
    "            alpha=1 if sample == \"test\" else 0.7,\n",
    "            label=\"%s (%s)\" % (scorer, sample),\n",
    "        )\n",
    "\n",
    "    best_index = np.nonzero(results[\"rank_test_%s\" % scorer] == 1)[0][0]\n",
    "    best_score = (\n",
    "        -results[\"mean_test_%s\" % scorer][best_index]\n",
    "        if scoring[scorer] == \"neg_log_loss\"\n",
    "        else results[\"mean_test_%s\" % scorer][best_index]\n",
    "    )\n",
    "\n",
    "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "    ax.plot(\n",
    "        [\n",
    "            X_axis[best_index],\n",
    "        ]\n",
    "        * 2,\n",
    "        [0, best_score],\n",
    "        linestyle=\"-.\",\n",
    "        color=color,\n",
    "        marker=\"x\",\n",
    "        markeredgewidth=3,\n",
    "        ms=8,\n",
    "    )\n",
    "\n",
    "    # Annotate the best score for that scorer\n",
    "    ax.annotate(\"%0.2f\" % best_score, (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e52c3bfb-4325-4c27-9f8e-5514dae799c2",
    "_uuid": "b3d12ca129d816d2434e74ed6574f829f826c3fc"
   },
   "outputs": [],
   "source": [
    "# final_test['Survived'] = log_clf.predict(final_test[Selected_features])\n",
    "# final_test['PassengerId'] = test_df['PassengerId']\n",
    "# submission = final_test[['PassengerId','Survived']]\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# submission.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
